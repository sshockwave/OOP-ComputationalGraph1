# 第二阶段扩展说明

## 实现的功能

第二阶段基础需求：
* 提交第一阶段的main.cpp，并保证仍能通过第一阶段的测试（占5%）
* 实现用于调试的Assert运算、实现捆绑Bind运算（占5%）
* 实现链式求导功能（占10%）
* 实现牛顿迭代法解方程（占5%）

第二阶段拓展需求：
* 实现给Variable赋值的Assign运算（最多+10%）
* 实现完整的自动求导功能，需要支持的运算符有-，/，sin，exp，log，Print，Assert，Bind，比较运算符（最多+10%）
* 运算图的session和存取功能，实现session与parameter值的绑定 (最多+10%)；并能够从文件存储和读取session中的parameter的值（最多+5%）
* 实现梯度下降求优化最小二乘法对于自变量有多个的情况（最多+20%)

需求以外的功能：
* 允许测试一次涉及2次求导的eval，允许求高阶导
* 添加了cos函数
* 实现了cos，tanh，sigmoid，assign，cond的自动求导功能

所有实现的功能都有对应测试数据，在`test/`目录下。

大部分功能按照实验文档要求实现。以下介绍一些关键步骤的实现方式以及实验文档中未定义行为的具体实现。

### 求导

我们创建了一个`Gradient_Node`类来记录某个变量（不妨记为`f`）上的导数。将`f`作为参数构造一个`Gradient_Node`实例之后，即可查询`f`对任意变量的偏导。

在`Gradient_Node`构造函数中，先对计算图进行拓扑排序，而后按照拓扑序依次处理每个节点。每个节点实现自己自身的`propagate_grad`函数，用于将自己的偏导传递给依赖的节点。当一个节点的所有前驱节点都向自己贡献之后，再处理自己。

对于一些特殊函数的求导处理：
* Print: 由于这个操作返回数本身，所以求导时认为print与单位函数e(x)=x无异；
* Logic: 由于逻辑运算符的输出是分段的，在很多位置的导数未定义；另外，输入在小范围内变动对logic输出无影响，故认为求导结果总是返回0；
* Condition: 条件语句将根据求导时的条件结果决定导数是否为0；如`a?sin(b):c`对b求导的结果在a>0时为cos(b)，在a<=0时，因为输出的值与b无关，对b求导的值为0；对a求导与Logic求导类似，总为0。
* Assert: 输出始终为0，所以导数也始终为0.
* Bind: 与Print类似。
* Assign: 作为被求导元素时，与Print类似，assign右值的偏导与assign操作符相同。但是如果某个Assign操作被某些节点的偏导值依赖，则那个元素被求导的时候可能会进行这个assign操作；这种情况较易出现隐蔽问题，不建议使用。

基本需求中的求导测试使用了下发样例；扩展需求中所有可求导函数的单元测试在`test/stage2/more_grad`中。

### 牛顿迭代法

对于导数为0情况，程序会放弃迭代并直接使用上一次迭代的值作为当前迭代的答案。相应测试数据见`test/newton/corner_cases/divide_zero`。

对于牛顿迭代法不一定能找到解（如无解的一元二次方程）的情况，这时牛顿迭代法会在极值左右震荡。相应测试数据见`test/newton/corner_cases/oscillate`。

### 给Variable赋值的Assign运算

在Graph中新建一个`map<Basic_Node*,float>set_variable`变量，记录在本轮计算中被重新赋值的Variable类对象以及所赋的值，并在本轮结束后更新其`value`,并清空`set_variable`
 
### Session

Session类存储了Variable名字到float的映射。Session类由标准库的istream和ostream负责输入输出，配合fstream可以非常方便地将数据存储到文件或从文件读取。当然也可以使用stringstream来将session序列化。

在`Graph`类中，`Graph::save`将数据存储到`Session`，`Graph::restore`从`Session`中恢复数据。

Session只存储当前名字有效的Variable。如果一个Variable的名字被覆盖，那么它不会被存储进Session中。

_我们考虑过使用指针作为identifier，但这样存储的session在当前程序结束之后就失效了。使用名字作为identifier可以实现所有功能，所以我们没有考虑其他的方案。_

在测试时，我们给主程序添加了`SAVEFILE {filename}`和`READFILE {filename}`两个命令，分别表示将当前的variable存入和读取到文件中。相应测试数据在`test/stage2/session`中。

### 梯度下降法

求梯度是梯度下降法的标准内容，这里不再赘述。实现梯度下降法的过程中，也并未涉及框架设计，只是单纯地调用库接口。

在测试梯度下降法的时候，由于向量较多、数据范围较大，存在梯度过大导致解在最优点附近震荡甚至越界至`nan`的问题。经测试，设置较小的步长可以解决该问题，但是收敛速度较慢。

通过查阅网上的资料（资料为转载，原出处未考证），我们实现了带动量的下降算法。简单来说，该算法将每次移动的向量加上了上一次移动的向量乘一个0到1之间的系数，使得在相邻几次下降同向时有较快的下降速度。该算法通过了我们所有随机的测试数据，见`test/gradient_descent`。

## 对原库实现的更改

为了实现扩展功能，我们新增了一些接口，但并没有更改任何原有接口。部分原有实现被修改，以下是我们的更改内容。

在代码上的具体改动可以[使用git查看对比](https://github.com/sshockwave/OOP-ComputationalGraph1/compare/2.0.0-alpha...master)。

### 输入输出部分

原库将输入和输出封装在了库中，而主程序仅仅是简单地调用了库的几个接口。因此，我们第一、第二阶段的主程序完全相同。

我们需要添加功能时，只能修改库的`creat_nodes`、`commands`、`crossroad`、`initialize_operator`系列函数。

### 缓存清空问题

在原库的实现中，缓存清空(clear_buffer)是递归进行的，而这个递归过程没有记忆化。

举例说明：对于以下一张图，
```
a0=1
a1=a0+a0
a2=a1+a1
```
清空a2时，会递归清空a1两次，而每清空一次a1都要递归清空a0两次。这样清空的复杂度很容易就被卡到指数级。要保持原有clear_buffer不变的含义不变，我们提出了三种方案：

* 进行全局清空或在全局存储需要局部清空的节点；
* 引入一个新的time tag来标记是否已经清空；
* 引入一个“已清空”标记，但这个“已清空”标记本身还需要清空，故这个方案不可行。

另外一个需要考虑的问题：在原库的实现中，完成一轮计算后进行清空是沿着计算的target回去清空的，所以如果某个placeholder的值没有被target依赖，那么placeholder就不会被清空。这在placeholder给充分的条件下不会出问题，但如果在某些情况中，placeholder没给全，此时这个程序就不能正常地报出“placeholder missing”错误。

但为了尽量减少对原库的改动，在我们的实现中并没有选择新增time tag，而是进行了全局清空。`Graph::reset_state`表示清空整张图，`Basic_Node::reset_state`表示清空该节点。对于一些不应该被清空的节点（如`Constant_Node`），重载了`reset_state`。

### 内存回收问题

在Graph类的initialize_operator系列函数中，原库希望的实现回收方法为：如果出现名字覆盖现象，那么就将旧节点放入`abandoned`列表。

原库的实现并非如此。原库进行的判断是，如果运算的节点和新节点同名，那么将运算的节点放入`abandoned`列表中。例如`a = a + b`中，右边的`a`会被放入`abandoned`列表中。

但是对于以下计算图：
```
a = 3
b = a + a
a = b * b
```
原来的`a=3`就没有被放入`abandoned`列表。

另外，Data_Node还负责释放内存，这与Operation_Node的功能不一致，易造成混乱。在后面的实现中，不能明确调用Gradient_Node所提供接口的对象，故无法决定谁回收该节点内存。这样不一致的行为若不修改，只能在新增的库中增加大量对外部的特判，导致耦合性大大增强。

我们的解决方案为，将所有的节点资源交由Graph来释放。在新建节点的时候，就在Graph中注册这个节点；在Graph被销毁的时候，Graph将释放`abandoned`和`item`中的所有指针，这些指针不能有重复。

这部分新增了若干接口`add_node`、`set_new_item`，并对原库的实现进行了较大的修改，主要体现在创建并存储节点的`initialize_operator`的系列函数中。但是原有接口的signature和含义都没有变化。

### 计算图结构

通过对原库代码的阅读，发现每一个节点在加进Graph中之前，都在外面套了一层placeholder。这层placeholder起到了几个作用：防止变量重复计算、给变量赋予名字。这样设计的好处在于不需要对每个Operation Node都实现`get_name`、`get_type`函数。但是这样会极大降低性能，Placeholder的作用也十分模糊。

为了对原库的变更最小化，我们并没有更改原库的这一架构。但是在我们拓展的Gradient_Node中，我们省略了这一层placeholder，没有与原库保持一致。

## 实验分析与总结

在第二阶段的实现中，我们修复了大量的bug，分离了每个类的职责（见对原库的修改），使得结构更加扁平、更加清晰（见[第二阶段代码结构.md](./第二阶段代码结构.md)）。

更改后内存管理十分简洁。创建新节点后，只需在Graph中注册一下，便不再需要担心内存回收问题。如果要进一步优化结构，可以使用工厂模式，所有新建节点的操作也由工厂Graph进行。但这需要使用变长模板来囊括每个类的构造函数，因此要对原库进行大幅修改，所以最后并未实现。

在扩展节点类时，我们遵循了原库的设计模式，对相应类进行继承，保持了代码结构的一致性。

求导部分，每个类通过重载`propagate_grad`函数自定义求导行为，具有较好的可扩展性。反向传播算法使用广搜+拓扑排序，不容易栈溢出，性能较好。但是原库的求值部分不够优秀，所以反向传播算法不是瓶颈。

在Graph类中，我们修改了原库`initialize_operator`的实现，将繁琐的节点添加操作抽象成函数，不仅修正了内存管理的bug，还提高了代码的复用性，使代码更简洁易懂。

原库的`Graph::string_to_int`在STL中有实现，可以考虑删去。但为了保持接口兼容性我们没有做修改。

`Session`类中的文件存取我们使用了兼容STL的iostream，与现有大量代码接轨，扩展性非常好，可以接上标准输入输出流、文件流、字符串流或自定义流。

因为实现简单，所以从结构上来看比较容易上手，但也因此运行的效率低下（如每次计算之前都需要进行整张图的reset）。此库作为计算图原理的学习展示库尚可，但在工业中使用较为吃力。

### 关于项目

项目使用`g++ -MM`自动生成依赖，添加了大量测试数据和自动化脚本；使用github平台同步代码，并在circle-ci上进行自动化测试。在后期开发中，这些工具帮助我们在写第二阶段代码的同时保证第一阶段代码的正确性，大大提高了开发的效率和代码的鲁棒性。

一方面，原库的漏洞较多，我们花费了大量的时间调试原库，其中许多较隐秘的bug甚至需要我们完整分析原库代码，具体内容在前面已经提到过。另一方面，原库设计的接口职责不清晰，使用难度较大：如简单的创建节点操作需要经过`initialize_operator_1`、`initialize_operator_2`、`initialize_operator_3`这三个函数进行，根据运算符的参数数量具体选择调用的函数，调用极其繁琐。重载加减乘除运算符（或提供更简洁的函数接口）是第一阶段的基础需求，但除了我们组以外，我们没有在下发的代码中看到有完成的。以上两个原因导致我们没有能够实现更多更高级的功能。

我们认为在实际项目中，如果后续保留原库的实现需要所花费的精力比重构基础库要大得多，不如重新开发一次，然后提供原库的兼容接口。但是由于要求少修改原库，而选自己的库要扣分，所以才在原库上顽强奋斗。
